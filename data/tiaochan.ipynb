{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "print('opencv版本: ', cv2.__version__)\n",
    "\n",
    "\n",
    "def bgr_rgb(img):\n",
    "    (r, g, b) = cv2.split(img)\n",
    "    return cv2.merge([b, g, r])\n",
    "\n",
    "def preprocess(img11, img21, filter=None, meanfilter_time1=0, meanfilter_time2=0):\n",
    "    img1 = img11.copy()\n",
    "    img2 = img21.copy()\n",
    "\n",
    "    if filter:\n",
    "        if filter == \"gray\":\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        if filter == \"oldyellow\":\n",
    "            img2 = retro_style(img2)\n",
    "\n",
    "    if meanfilter_time1 > 0:\n",
    "        for i in range(meanfilter_time1):\n",
    "            img1 = cv2.blur(img1, (3, 3))\n",
    "    if meanfilter_time2 > 0:\n",
    "        for i in range(meanfilter_time2):\n",
    "            img2 = cv2.blur(img2, (3, 3))\n",
    "\n",
    "    plt.figure(1, dpi=200)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img1)\n",
    "    plt.figure(2, dpi=200)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img2)\n",
    "\n",
    "    return img1,img2\n",
    "\n",
    "def detect(img11, img21, sf=\"sift\", filter=None, meanfilter_time1=0, meanfilter_time2=0, limit=0.6):\n",
    "\n",
    "    img1 = img11.copy()\n",
    "    img2 = img21.copy()\n",
    "\n",
    "    if filter:\n",
    "        if filter == \"gray\":\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        if filter == \"oldyellow\":\n",
    "            img2 = retro_style(img2)\n",
    "\n",
    "    if meanfilter_time1 > 0:\n",
    "        for i in range(meanfilter_time1):\n",
    "            img1 = cv2.blur(img1, (3, 3))\n",
    "    if meanfilter_time2 > 0:\n",
    "        for i in range(meanfilter_time2):\n",
    "            img2 = cv2.blur(img2, (3, 3))\n",
    "\n",
    "    # plt.figure(1, dpi=200)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.imshow(img1)\n",
    "    # plt.figure(2, dpi=200)\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.imshow(img2)\n",
    "\n",
    "    if sf==\"sift\":\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "    elif sf==\"surf\":\n",
    "        sift = cv2.xfeatures2d.SURF_create()\n",
    "    elif sf==\"orb\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"无效算法\")\n",
    "        return None,None\n",
    "    \n",
    "    # 使用SIFT查找关键点和描述符\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    # BFMatcher 使用默认参数\n",
    "    bf = cv2.BFMatcher()\n",
    "    rawmatches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    kps1 = np.float32([kp.pt for kp in kp1])\n",
    "    kps2 = np.float32([kp.pt for kp in kp2])\n",
    "    matches = []\n",
    "    good = []\n",
    "    # 遍历初始匹配点\n",
    "    for m in rawmatches:\n",
    "        # 应用ratio测试，选出符合条件的匹配点(Lowe's ratio test)\n",
    "        # 取图像1中的某个关键点，并找出其与图像2中距离最近的前两个关键点，在这两个关键点中，若最近的距离除以次近的距离小于某个阈值，则接受这一对匹配点。\n",
    "        # 实验结果表明ratio取值（limit）在0.5~0.6为最佳\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * limit:\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "            good.append([m[0]])\n",
    "     \n",
    "    # 使用cv2.drawMatchesKnn将匹配点画出\n",
    "    img3 = cv2.drawMatchesKnn(img11, kp1, img21, kp2, good, None, flags=2)\n",
    "    \n",
    "    # 计算出一个单应性变换至少需要4对匹配点\n",
    "    if len(matches) > 4:\n",
    "        # 构造这两组点坐标为对应形式\n",
    "        ptsA = np.float32([kps1[i] for (_, i) in matches])\n",
    "        ptsB = np.float32([kps2[i] for (i, _) in matches])\n",
    "\n",
    "        # 计算两组点之间的单应性变换矩阵以及每个匹配点的状态\n",
    "        (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, 4)\n",
    "\n",
    "    else:\n",
    "        print(\"没有足够的匹配点\")\n",
    "        return (matches, None, None, bgr_rgb(img3))\n",
    "    return (matches, H, status, bgr_rgb(img3))\n",
    "\n",
    "\n",
    "def opt(image_a, image_b, sf=\"sift\", filter=None, meanfilter_time1=1, meanfilter_time2=1, limit=0.6):\n",
    "\n",
    "    (matches, H, status, matchesimg) = detect(\n",
    "        image_a, image_b, sf, filter, meanfilter_time1, meanfilter_time2, limit)\n",
    "\n",
    "    if H.any():\n",
    "        # 使用单应性变换矩阵进行原图的透视变换，将图1投影到图2大小的初始图上\n",
    "        result = cv2.warpPerspective(image_a, H, (image_b.shape[1], image_b.shape[0]))\n",
    "        result = bgr_rgb(result)\n",
    "        img = bgr_rgb(image_b)\n",
    "        \n",
    "        # 将图二上对应位置替换成投影后的图1\n",
    "        for i in range(image_b.shape[0]):\n",
    "            for j in range(image_b.shape[1]):\n",
    "                if sum(result[i, j]) > 0:\n",
    "                    img[i, j] = result[i, j]\n",
    "        \n",
    "        return matchesimg, img\n",
    "    \n",
    "    print(\"失败\")\n",
    "    return matchesimg, None\n",
    "\n",
    "def orb_detect(image_a, image_b):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(image_a, None)\n",
    "    kp2, des2 = orb.detectAndCompute(image_b, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    matches = bf.match(des1, des2)\n",
    "    rawmatches = sorted(matches, key=lambda x: x.distance)\n",
    "    img3 = cv2.drawMatches(image_a, kp1, image_b, kp2,\n",
    "                           rawmatches[:10], None, flags=2)\n",
    "    goodPoints = matches[:10] if len(matches) > 10   else matches[:]\n",
    "\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in goodPoints]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in goodPoints]).reshape(-1, 1, 2)\n",
    "    \n",
    "    M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 4)\n",
    "    \n",
    "    return (matches, M, mask ,bgr_rgb(img3))\n",
    "# 泛黄老照片效果\n",
    "def retro_style(img):\n",
    "    img2 = img.copy()\n",
    "    height, width, n = img.shape\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b = img[i, j][0]\n",
    "            g = img[i, j][1]\n",
    "            r = img[i, j][2]\n",
    "            # 计算新的图像中的RGB值\n",
    "            B = int(0.273 * r + 0.535 * g + 0.131 * b)\n",
    "            G = int(0.347 * r + 0.683 * g + 0.167 * b)\n",
    "            R = int(0.395 * r + 0.763 * g + 0.188 * b) \n",
    "            # 约束图像像素值，防止溢出\n",
    "            img2[i, j][0] = max(0, min(B, 255))\n",
    "            img2[i, j][1] = max(0, min(G, 255))\n",
    "            img2[i, j][2] = max(0, min(R, 255))\n",
    "    return img2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#快速调参函数\n",
    "if __name__ == '__main__': \n",
    "    # 加载图像\n",
    "    for i in range(20):\n",
    "        # image_a = cv2.imread('picture{}/1.png'.format(1))\n",
    "        # image_b = cv2.imread('picture{}/2.png'.format(1))\n",
    "        # sf,filter,meanfiler_time1,meanfiler_time2,ratiolimit = np.load('picture{}/parm.npy'.format(i+1),allow_pickle=True)\n",
    "        # print(sf,filter,meanfiler_time1,meanfiler_time2,ratiolimit)\n",
    "        # matchesimg, img = opt(image_a, image_b, sf, filter, int(meanfiler_time1),int(meanfiler_time2),float(ratiolimit))\n",
    "        image_a = cv2.imread('1.png')\n",
    "        image_b = cv2.imread('2.png')\n",
    "        matchesimg, img = opt(image_a, image_b, \"sift\", \"gray\", 1, 1, 0.8+i/100)\n",
    "\n",
    "        # plt.figure(3, dpi=200)\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.imshow(matchesimg)\n",
    "        # plt.savefig(\"picture{}/matches.png\".format(i+1))\n",
    "\n",
    "        if img.any():\n",
    "            plt.figure(i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"ratiolimit={}\".format(0.8+i/100))\n",
    "            # plt.savefig(\"picture{}/result.png\".format(i+1))\n",
    "\n",
    "        plt.show()\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift gray 1 1 0.6\n"
     ]
    }
   ],
   "source": [
    "#保存参数\n",
    "np.save('parm.npy',(\"sift\", \"gray\", 1, 1, 0.6))\n",
    "sf,filter,meanfiler_time1,meanfiler_time2,ratiolimit=np.load('parm.npy',allow_pickle=True)\n",
    "print(sf,filter,meanfiler_time1,meanfiler_time2,ratiolimit)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88ef2877b3f67c97f17696932a7eeae144f391b415f4d79bae633a0616ef5b55"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
